# ========= –ó–ê–î–ê–ù–ò–ï –î–õ–Ø CODEX =========
**–¶–µ–ª—å:** —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ö–ê–†–ö–ê–° –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã ¬´Invest-Score¬ª.
–†–µ–∞–ª–∏–∑—É–π —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –∑–∞–≥–ª—É—à–∫–∏ –∏ —Ç–æ—á–∫–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è (no business-logic).
–§–∞–π–ª—ã –¥–æ–ª–∂–Ω—ã —Å—Ä–∞–∑—É –∑–∞–ø—É—Å–∫–∞—Ç—å—Å—è (`docker-compose up -d` ‚Üí 200 OK), –Ω–æ
–≤—Å–µ —Å–ª–æ–∂–Ω—ã–µ –º–µ—Å—Ç–∞ (Spark, Fabric, ML) –æ—Å—Ç–∞–≤—å –∫–∞–∫ TODO-–∑–∞–≥–ª—É—à–∫–∏.

## 0. –°—Ç–µ–∫
* Backend: Python 3.11, FastAPI
* Frontend: —á–∏—Å—Ç—ã–π HTML + Vanilla JS (index.html ‚Üî few pages)
* –ë—Ä–æ–∫–µ—Ä: Kafka (Confluent image)
* DB: PostgreSQL + Redis
* Dev-–∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞: Docker Compose

## 1. –î–µ—Ä–µ–≤–æ –ø—Ä–æ–µ–∫—Ç–∞
```
invest-score/
 ‚îú docker-compose.yml
 ‚îú README.md
 ‚îú backend/
 ‚îÇ   ‚îú api-gateway/
 ‚îÇ   ‚îÇ   ‚îú app.py        # FastAPI gateway (auth, routing)
 ‚îÇ   ‚îÇ   ‚îî requirements.txt
 ‚îÇ   ‚îú ingest/
 ‚îÇ   ‚îÇ   ‚îú financial_ingest.py
 ‚îÇ   ‚îÇ   ‚îú social_ingest.py
 ‚îÇ   ‚îÇ   ‚îî requirements.txt
 ‚îÇ   ‚îú model-service/
 ‚îÇ   ‚îÇ   ‚îú api.py        # FastAPI: /predict, /shap
 ‚îÇ   ‚îÇ   ‚îú train.py      # TODO placeholder
 ‚îÇ   ‚îÇ   ‚îî requirements.txt
 ‚îÇ   ‚îî simulation-service/
 ‚îÇ       ‚îú app.py        # FastAPI: /what-if, /monte-carlo
 ‚îÇ       ‚îî requirements.txt
 ‚îú frontend/
 ‚îÇ   ‚îú index.html        # login
 ‚îÇ   ‚îú companies.html    # table-–∑–∞–≥–ª—É—à–∫–∞
 ‚îÇ   ‚îú company.html      # SHAP / –≥—Ä–∞—Ñ–∏–∫–∏
 ‚îÇ   ‚îú scenario.html     # sliders + histogram
 ‚îÇ   ‚îî stream.html       # live data
 ‚îú css/style.css
 ‚îî js/ (login.js, nav.js, companies.js, ...)
```

## 2. –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∫–∞–∂–¥–æ–º—É —Å–µ—Ä–≤–∏—Å—É
* **FastAPI** –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å `/health` 200 OK.
* –í `requirements.txt` –ø—Ä–æ–ø–∏—Å–∞—Ç—å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.
* –í–Ω—É—Ç—Ä–∏ –∫–æ–¥–∞ –¥–æ–±–∞–≤–∏—Ç—å `TODO:` –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –≥–¥–µ –±—É–¥–µ—Ç —Ä–µ–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞.
* –í—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è —á–∏—Ç–∞—Ç—å —á–µ—Ä–µ–∑ `os.getenv` (–¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞—Å—Ç—å —Å docker-compose).

## 3. docker-compose.yml
* Zookeeper + Kafka (confluentinc/cp-kafka:7.5)
* postgres:15, redis:7
* build –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞ –∫–∞–∂–¥—ã–π —Å–µ—Ä–≤–∏—Å (backend/*)
* —Ç–æ–º `pgdata` (named volume)
* —Å–µ—Ç–∏: default bridge
* –¥–ª—è gateway –ø—Ä–æ–±—Ä–æ—Å–∏—Ç—å –ø–æ—Ä—Ç 8000; –¥–ª—è —Å—Ç–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ nginx ‚Äî 3000

## 4. Backend –¥–µ—Ç–∞–ª–∏
### 4.1 api-gateway/app.py
```python
# FastAPI, auth = login/password "admin"/"admin123"
# JWT –Ω–∞ HS256, SECRET = os.getenv("JWT_SECRET","devsecret")
# —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã: POST /login, GET /companies (–∑–∞–≥–ª—É—à–∫–∞), WS /ws/ratings (echo)
```
### 4.2 ingest/*
* financial_ingest.py: –∫–∞–∂–¥—ã–µ 60 —Å —á–∏—Ç–∞–µ—Ç /data/*.csv –∏ —à–ª—ë—Ç JSON –≤ Kafka topic `financial_data`.
* social_ingest.py: –∏–º–∏—Ç–∏—Ä—É–µ—Ç –ø–æ—Ç–æ–∫; –∫–∞–∂–¥—ã–π 10 —Å –ø—É–±–ª–∏–∫—É–µ—Ç —Ñ–µ–π–∫–æ–≤—ã–π —Ç–≤–∏—Ç –≤ topic `social_data`.

### 4.3 model-service/api.py
* `POST /predict` ‚Äî –ø—Ä–∏–Ω–∏–º–∞–µ—Ç `{features:[numbers...]}` ‚Üí –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç fixed `"score": 75`.
* `POST /shap` ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç dummy –º–∞—Å—Å–∏–≤ –∏–∑ 5 SHAP –∑–Ω–∞—á–µ–Ω–∏–π.

### 4.4 simulation-service/app.py
* `/what-if` ‚Äî echo `{score: 80}`
* `/monte-carlo` ‚Äî –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç 500 —Å–ª—É—á. —á–∏—Å–µ–ª –≤–æ–∫—Ä—É–≥ 75, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç mean, std, hist[10].

## 5. Frontend (Vanilla JS)
* –ø–æ–¥–∫–ª—é—á–∏—Ç—å Chart.js –∏–∑ CDN.
* companies.html ‚Äî –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–∞–±–ª–∏—Ü—É –∏–∑ 5 –∑–∞—Ö–∞—Ä–¥–∫–æ–∂–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π.
* scenario.html ‚Äî 3 range-slider, –∫–Ω–æ–ø–∫–∞ ¬´simulate¬ª ‚Üí —Ä–∏—Å—É–µ—Ç –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É.
* company.html ‚Äî SHAP bar + line chart (—Ä–∞–Ω–¥–æ–º–Ω—ã–µ —Ç–æ—á–∫–∏).
* stream.html ‚Äî textarea + button ¬´NEW RECORD¬ª ‚Üí –ø–∏—à–µ—Ç –≤ LocalStorage –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç.

## 6. README.md
–í–∫–ª—é—á–∏:
```
### Quick Start
docker-compose up -d
open http://localhost:3000
login: admin / admin123
```

============ END ============

> *–í—ã–≤–µ–¥–∏ –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª –æ—Ç–¥–µ–ª—å–Ω—ã–º ```bash path/filename``` –±–ª–æ–∫–æ–º, –ø–æ—Ç–æ–º –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ.*

+__+_____


–ù–∏–∂–µ ‚Äï –≥–æ—Ç–æ–≤—ã–π –º–∏–Ω–∏-—Å–∞–π—Ç-–º–∞–∫–µ—Ç (—á–∏—Å—Ç—ã–π HTML + Vanilla JS + Chart.js + –æ–¥–Ω–∞ ttf-—Ç–µ–º–Ω–∞—è CSS-—Ç–µ–º–∞)-—Å–æ –≤—Å–µ–º–∏ –ø—è—Ç—å—é —ç–∫—Ä–∞–Ω–∞–º–∏.
–°–∫–∞—á–∞–π—Ç–µ –∫–æ–¥, –ø–æ–ª–æ–∂–∏—Ç–µ –≤ –ø–∞–ø–∫—É site/, –æ—Ç–∫—Ä–æ–π—Ç–µ index.html ‚Äï –∏ –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ñ–ª–∞–π–Ω.

‚Ä¢ –õ–æ–≥–∏–Ω/–ø–∞—Ä–æ–ª—å: admin / admin123
‚Ä¢ –ù–∞–≤–∏–≥–∞—Ü–∏—è —á–µ—Ä–µ–∑ –æ–±—ã—á–Ω—ã–µ —Å—Å—ã–ª–∫–∏ (href).
‚Ä¢ Chart.js –ø–æ–¥–∫–ª—é—á—ë–Ω –∏–∑ CDN.
‚Ä¢ SHAP-–±–∞—Ä –∏ Monte-–ö–∞—Ä–ª–æ-–≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ —Ä–µ–∞–≥–∏—Ä—É—é—Ç –Ω–∞ —Å–ª–∞–π–¥–µ—Ä—ã.
‚Ä¢ Data Stream-—Å—Ç—Ä–∞–Ω–∏—Ü–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –¥–æ–±–∞–≤–ª—è—Ç—å/—É–¥–∞–ª—è—Ç—å –∑–∞–ø–∏—Å–∏ –ª–æ–∫–∞–ª—å–Ω–æ (–≤ LocalStorage, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–æ–ø–∞–¥–∞–ª–∏ –ø—Ä–∏ F5).

1 | –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞
pgsql
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
site/
‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îî‚îÄ‚îÄ chart.min.js          (CDN –º–æ–∂–Ω–æ –Ω–µ —Å–∫–∞—á–∏–≤–∞—Ç—å)
‚îú‚îÄ‚îÄ css/
‚îÇ   ‚îî‚îÄ‚îÄ style.css
‚îú‚îÄ‚îÄ js/
‚îÇ   ‚îú‚îÄ‚îÄ login.js
‚îÇ   ‚îú‚îÄ‚îÄ nav.js                (–≤—ã–¥–µ–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –ø—É–Ω–∫—Ç–∞)
‚îÇ   ‚îú‚îÄ‚îÄ companies.js
‚îÇ   ‚îú‚îÄ‚îÄ scenario.js
‚îÇ   ‚îú‚îÄ‚îÄ company.js
‚îÇ   ‚îî‚îÄ‚îÄ stream.js
‚îú‚îÄ‚îÄ index.html                (Login)
‚îú‚îÄ‚îÄ companies.html            (Dashboard)
‚îú‚îÄ‚îÄ company.html              (Company detail)
‚îú‚îÄ‚îÄ scenario.html             (Scenario modeller)
‚îî‚îÄ‚îÄ stream.html               (Data stream)
2 | –§–∞–π–ª—ã
2.1 css/style.css
css
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
/* –¢—ë–º–Ω–∞—è —Ç–µ–º–∞ –ø–æ-—É–º–æ–ª—á–∞–Ω–∏—é */
body{
  margin:0;font-family:-apple-system,Segoe UI,Roboto,Helvetica,Arial,sans-serif;
  background:#111;color:#f0f0f0;
}
a{color:#16a34a;text-decoration:none} a:hover{text-decoration:underline}
.container{max-width:900px;margin:0 auto;padding:32px}

/* –∫–∞—Ä—Ç–æ—á–∫–∏/–±–ª–æ–∫–∏ */
.card{background:#1b1b1b;border-radius:8px;padding:24px;margin-bottom:24px}

/* —Ç–∞–±–ª–∏—Ü–∞ */
table{width:100%;border-collapse:collapse}
th,td{padding:12px;border-bottom:1px solid #333;text-align:left}
tr:hover{background:#222}

/* –∫–Ω–æ–ø–∫–∏ */
button{padding:10px 20px;border:0;border-radius:6px;background:#16a34a;color:#fff;cursor:pointer}
button.secondary{background:#1f2937}
button:disabled{opacity:.5;cursor:default}

/* –∏–Ω–ø—É—Ç—ã */
input,select{
  padding:10px;border:1px solid #444;border-radius:6px;background:#1b1b1b;color:#f0f0f0;width:100%;
}
input[type=range]{width:100%}

/* —Å–≤–µ—Ç–ª–∞—è —Ç–µ–º–∞ –¥–ª—è –¥–µ—Ç–∞–ª–µ–π/stream */
.light body{background:#f6f6f7;color:#0f0f0f}
.light .card{background:#fff;border:1px solid #e5e7eb}
.light table tr:hover{background:#f3f4f6}
.light input, .light select{background:#fff;color:#0f0f0f;border:1px solid #d1d5db}
.light button.secondary{background:#e5e7eb;color:#111}
2.2 js/login.js
js
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
document.getElementById("loginForm").addEventListener("submit", e => {
  e.preventDefault();
  const u = e.target.user.value.trim();
  const p = e.target.pass.value.trim();
  if (u === "admin" && p === "admin123") {
    sessionStorage.setItem("auth", "ok");
    location.href = "companies.html";
  } else {
    alert("Bad credentials");
  }
});
2.3 js/nav.js
js
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
// –≤—ã–¥–µ–ª—è–µ–º active –≤ –º–µ–Ω—é
const here = location.pathname.split("/").pop();
document.querySelectorAll("nav a").forEach(a=>{
  if(a.getAttribute("href")===here){a.classList.add("active")}
});
2.4 js/companies.js
js
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
if(!sessionStorage.getItem("auth"))location.href="index.html";

const tbody = document.querySelector("#tbl");
const demo = [
  {name:"Alpha Corp", sector:"Industrials", rating:"AAA", prob:"98.6%"},
  {name:"Beta Industries", sector:"Consumer Goods", rating:"AA", prob:"90.1%"},
  {name:"Gamma PLC", sector:"Financials", rating:"A", prob:"78.4%"},
  {name:"Delta Ltd", sector:"Technology", rating:"BBB", prob:"65.2%"},
  {name:"Epsilon Inc", sector:"Healthcare", rating:"BBB", prob:"61.8%"}
];

demo.forEach(c=>{
  const tr=document.createElement("tr");
  tr.innerHTML=`<td><a href="company.html?c=${encodeURIComponent(c.name)}">${c.name}</a></td>
                <td>${c.sector}</td><td>${c.rating}</td><td>${c.prob}</td>`;
  tbody.appendChild(tr);
});
2.5 js/scenario.js
js
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
if(!sessionStorage.getItem("auth"))location.href="index.html";

const sliders=document.querySelectorAll("input[type=range]");
const result=document.getElementById("result");
const ctx=document.getElementById("hist").getContext("2d");

let chart = new Chart(ctx,{
  type:"bar",
  data:{labels:[],datasets:[{label:"freq",data:[],backgroundColor:"#60a5fa"}]},
  options:{scales:{y:{beginAtZero:true}}}
});

function simulate(){
  const vals=[...sliders].map(s=>Number(s.value));
  // –ø—Ä–∏–º–∏—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å: base=80, –∫–∞–∂–¥–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ +/-10 –¥–∞—ë—Ç ¬±5 —Ä–µ–π—Ç–∏–Ω–≥–∞
  let score=80+vals.reduce((s,v)=>s+v*5,0);
  score=Math.max(0,Math.min(100,score));
  result.textContent= score>85?"AAA": score>70?"AA": score>55?"A":"BBB";

  // –≥–µ–Ω–µ—Ä–∏–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É
  const bins=15, arr=[];
  for(let i=0;i<500;i++){
    let sc=score+Math.random()*10-5;
    arr.push(Math.round(sc));
  }
  const hist=Array(bins).fill(0), step=100/bins;
  arr.forEach(v=>{const idx=Math.min(bins-1,Math.floor(v/step));hist[idx]++;});
  chart.data.labels=[...Array(bins)].map((_,i)=>Math.round(i*step));
  chart.data.datasets[0].data=hist; chart.update();
}

sliders.forEach(s=>{
  s.addEventListener("input",()=>{s.nextElementSibling.textContent=`${s.value}%`});
});
document.getElementById("run").addEventListener("click",simulate);
simulate();
2.6 js/company.js
js
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
if(!sessionStorage.getItem("auth"))location.href="index.html";
const params=new URLSearchParams(location.search);
const name=params.get("c")||"X Company";
document.getElementById("cname").textContent=name;

// —Ñ–µ–π–∫–æ–≤—ã–µ SHAP
const shapLabels=["Driver","Debt","Profit Margin","Expenses","Liquidity"];
const shapVals=[0.8,-0.4,0.32,0.2,0.12];

// –≥—Ä–∞—Ñ SHAP
new Chart(document.getElementById("shap"),{
  type:"bar",
  data:{labels:shapLabels,
        datasets:[{data:shapVals,
                   backgroundColor:shapVals.map(v=>v>0?"#3b82f6":"#ef4444")}]},
  options:{indexAxis:"y",plugins:{legend:{display:false}}}
});

// –ª–∏–Ω–∏—è –¥–æ—Ö–æ–¥–æ–≤
new Chart(document.getElementById("fin"),{
  type:"line",
  data:{
    labels:["Q1","Q2","Q3","Q4"],
    datasets:[
      {label:"Revenue",data:[120,180,160,220],borderColor:"#60a5fa",tension:.3},
      {label:"Net Income",data:[60,30,100,80],borderColor:"#10b981",tension:.3}
    ]
  },
  options:{plugins:{legend:{display:false}}}
});
2.7 js/stream.js
js
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
if(!sessionStorage.getItem("auth"))location.href="index.html";
const list=document.getElementById("list");
let store=JSON.parse(localStorage.getItem("stream")||"[]");
function render(){
  list.innerHTML="";
  store.forEach((m,i)=>{
    const tr=document.createElement("tr");
    tr.innerHTML=`<td>${m.ts}</td><td>${m.txt}</td>
                  <td><button class="secondary" data-i=${i}>üóë</button></td>`;
    list.appendChild(tr);
  });
}
render();
document.getElementById("add").addEventListener("click",()=>{
  const txt=document.getElementById("json").value.trim();
  if(!txt)return;
  store.unshift({ts:new Date().toLocaleString(),txt});
  localStorage.setItem("stream",JSON.stringify(store.slice(0,20)));
  render();
});
list.addEventListener("click",e=>{
  if(e.target.dataset.i!==undefined){
    store.splice(e.target.dataset.i,1);
    localStorage.setItem("stream",JSON.stringify(store));
    render();
  }
});
2.8 HTML-—Å—Ç—Ä–∞–Ω–∏—Ü—ã (–ø—Ä–∏–º–µ—Ä: companies.html)
html
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
<!DOCTYPE html><html lang="ru">
<head>
  <meta charset="UTF-8"><title>Companies</title>
  <link rel="stylesheet" href="css/style.css">
  <script src="assets/chart.min.js"></script>
</head>
<body>
<nav class="card">
  <a href="companies.html">Companies</a> |
  <a href="scenario.html">Scenarios</a> |
  <a href="stream.html">Data Stream</a>
</nav>

<div class="container">
  <h1>Companies</h1>
  <div class="card">
    <table><thead><tr>
      <th>Company</th><th>Sector</th><th>Rating</th><th>Probability</th>
    </tr></thead><tbody id="tbl"></tbody></table>
  </div>
</div>

<script src="js/nav.js"></script>
<script src="js/companies.js"></script>
</body></html>



1¬†|¬†–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
css
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
invest-score/
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ ingest/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ financial_ingest.py
‚îÇ   ‚îî‚îÄ‚îÄ social_ingest.py
‚îú‚îÄ‚îÄ nlp-service/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ spark-job/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ build.sbt
‚îÇ   ‚îî‚îÄ‚îÄ src/main/scala/StreamingJob.scala
‚îú‚îÄ‚îÄ model-service/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îî‚îÄ‚îÄ api.py
‚îú‚îÄ‚îÄ simulation-service/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ api-gateway/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îî‚îÄ‚îÄ auth.py
‚îî‚îÄ‚îÄ web-ui/          # —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π build React (vite)
    ‚îî‚îÄ‚îÄ ...
2¬†|¬†Docker‚ÄëCompose (–∫–æ—Ä–æ—Ç–∫–∞—è –≤–µ—Ä—Å–∏—è)
yaml
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
version: "3.9"
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on: [zookeeper]
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
    ports: ["9092:9092"]

  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: invest
      POSTGRES_USER: invest
      POSTGRES_PASSWORD: invest
    volumes: ["pgdata:/var/lib/postgresql/data"]
    ports: ["5432:5432"]

  redis:
    image: redis:7
    ports: ["6379:6379"]

  ingest:
    build: ./ingest
    depends_on: [kafka]
    env_file: .env

  nlp-service:
    build: ./nlp-service
    depends_on: [kafka]
    env_file: .env

  spark-job:
    build: ./spark-job
    depends_on: [kafka, postgres]
    environment:
      - KAFKA_BOOTSTRAP=kafka:9092

  model-service:
    build: ./model-service
    depends_on: [postgres]
    env_file: .env
    ports: ["8001:8001"]

  simulation-service:
    build: ./simulation-service
    depends_on: [model-service]
    ports: ["8002:8002"]

  api-gateway:
    build: ./api-gateway
    depends_on: [redis, postgres, model-service, simulation-service]
    env_file: .env
    ports: ["8000:8000"]

  web:
    image: nginx:1.25-alpine
    volumes:
      - ./web-ui/dist:/usr/share/nginx/html
    depends_on: [api-gateway]
    ports: ["3000:80"]

volumes:
  pgdata:
3¬†|¬†Ingest¬†Service¬†(Python)
requirements.txt
makefile
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
pandas==2.2.2
requests
kafka-python==2.0.2
feedparser
python-telegram-bot==20.7
tweepy==4.14.0
financial_ingest.py
python
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
"""
–ó–∞–¥–∞—á–∞: –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ —Å—á–∏—Ç—ã–≤–∞—Ç—å CSV/Excel –∏–∑ –ø–∞–ø–∫–∏ /data
–∏–ª–∏ –ø–æ REST‚ÄëAPI –∏ —Å–ª–∞—Ç—å –∑–∞–ø–∏—Å–∏ –≤ Kafka topic 'financial_data'
"""
import os, time, json
import pandas as pd
from kafka import KafkaProducer

BOOTSTRAP = os.getenv("KAFKA_BOOTSTRAP", "kafka:9092")
producer = KafkaProducer(bootstrap_servers=BOOTSTRAP,
                         value_serializer=lambda v: json.dumps(v).encode())

def process_file(path: str) -> None:
    df = pd.read_csv(path) if path.endswith(".csv") else pd.read_excel(path)
    for _, row in df.iterrows():
        msg = row.to_dict()
        producer.send("financial_data", msg)
    producer.flush()

if __name__ == "__main__":
    POLL = int(os.getenv("FIN_POLL_SEC", 3600))
    DATA_DIR = "/data"
    sent = set()
    while True:
        for f in os.listdir(DATA_DIR):
            abspath = os.path.join(DATA_DIR, f)
            if abspath not in sent:
                process_file(abspath)
                sent.add(abspath)
        time.sleep(POLL)
social_ingest.py
python
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
"""
–ü–æ—Ç–æ–∫ —Ç–≤–∏—Ç–æ–≤ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –∏ Telegram‚Äë—Å–æ–æ–±—â–µ–Ω–∏–π.
–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç JSON ‚Üí topic 'social_data'
"""

import os, json, asyncio
from datetime import datetime
from kafka import KafkaProducer
import tweepy
from telethon import TelegramClient, events

BOOTSTRAP = os.getenv("KAFKA_BOOTSTRAP", "kafka:9092")
producer = KafkaProducer(bootstrap_servers=BOOTSTRAP,
                         value_serializer=lambda v: json.dumps(v).encode())

# ---------- Twitter ----------
tw_auth = tweepy.OAuth2AppHandler(
    os.getenv("TW_API_KEY"), os.getenv("TW_API_SECRET"))
client = tweepy.Client(bearer_token=os.getenv("TW_BEARER"))

KEYWORDS = ["–ì–∞–∑–ø—Ä–æ–º", "–°–±–µ—Ä–±–∞–Ω–∫", "–õ—É–∫–æ–π–ª"]  # ‚Üê —Ä–∞—Å—à–∏—Ä—å—Ç–µ YAML‚Äë—Ñ–∞–π–ª–æ–º

class TWStream(tweepy.StreamingClient):
    def on_tweet(self, tweet):
        producer.send("social_data", {
            "source": "twitter",
            "text": tweet.text,
            "ts": tweet.created_at.isoformat()
        })

tw_stream = TWStream(bearer_token=os.getenv("TW_BEARER"))
# add rules once
tw_stream.add_rules([tweepy.StreamRule(k) for k in KEYWORDS])

# ---------- Telegram ----------
tg_api_id = os.getenv("TG_API_ID")
tg_api_hash = os.getenv("TG_API_HASH")
tg_client = TelegramClient("ingest", tg_api_id, tg_api_hash)

@tg_client.on(events.NewMessage(chats=os.getenv("TG_CHANNELS").split(",")))
async def handler(event):
    producer.send("social_data", {
        "source": "telegram",
        "text": event.raw_text,
        "ts": datetime.utcnow().isoformat()
    })

if __name__ == "__main__":
    # –∑–∞–ø—É—Å—Ç–∏–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    tg_client.start()
    asyncio.get_event_loop().create_task(tg_client.run_until_disconnected())
    tw_stream.filter(expansions=None)       # –±–ª–æ–∫–∏—Ä—É—é—â–∏–π
4¬†|¬†NLP‚ÄëService¬†(Python¬†+¬†FastAPI)
requirements.txt
makefile
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
fastapi
uvicorn[standard]
transformers==4.41.2
torch==2.2.2
pydantic
kafka-python
bertopic==0.16.0
app.py
python
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
"""
consumer 'social_data' ‚Üí NLP ‚Üí producer 'text_features'
GET /health 200 OK
"""

import os, json
from fastapi import FastAPI
from kafka import KafkaConsumer, KafkaProducer
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from bertopic import BERTopic
import torch

app = FastAPI()
BOOTSTRAP = os.getenv("KAFKA_BOOTSTRAP", "kafka:9092")

producer = KafkaProducer(bootstrap_servers=BOOTSTRAP,
                         value_serializer=lambda v: json.dumps(v).encode())

consumer = KafkaConsumer(
    "social_data",
    bootstrap_servers=BOOTSTRAP,
    value_deserializer=lambda m: json.loads(m.decode()),
    group_id="nlp"
)

# -------- –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π --------
tok = AutoTokenizer.from_pretrained("DeepPavlov/rubert-base-cased-sentiment")
sent_model = AutoModelForSequenceClassification.from_pretrained(
    "DeepPavlov/rubert-base-cased-sentiment").eval()

topic_model = BERTopic.load("ru_bertopic_model")  # –∑–∞—Ä–∞–Ω–µ–µ –¥–æ–æ–±—É—á–∏—Ç—å!

def analyse(text: str):
    inputs = tok(text, return_tensors="pt", truncation=True, max_length=128)
    with torch.no_grad():
        logits = sent_model(**inputs).logits
        proba = torch.softmax(logits, dim=1)[0]
    sentiment = {"neg": float(proba[0]), "neu": float(proba[1]),
                 "pos": float(proba[2])}
    topic, _ = topic_model.transform([text])
    return sentiment, int(topic[0])

@app.on_event("startup")
def start():
    import threading
    threading.Thread(target=loop, daemon=True).start()

def loop():
    for msg in consumer:
        text = msg.value["text"]
        sentiment, topic = analyse(text)
        out = {**msg.value,
               "sentiment": sentiment,
               "topic": topic}
        producer.send("text_features", out)

@app.get("/health")
def health():
    return {"status": "ok"}
5¬†|¬†Spark¬†Structured¬†Streaming¬†Job¬†(Scala¬†3)
build.sbt
sbt
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
ThisBuild / scalaVersion := "3.3.3"
libraryDependencies ++= Seq(
  "org.apache.spark" %% "spark-sql-kafka-0-10" % "3.5.1",
  "org.apache.spark" %% "spark-streaming" % "3.5.1",
  "org.postgresql"   %  "postgresql"      % "42.7.3"
)
StreamingJob.scala
scala
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

object StreamingJob:
  def main(args: Array[String]): Unit =
    val spark = SparkSession.builder
      .appName("InvestStream")
      .master(sys.env.getOrElse("SPARK_MASTER", "local[*]"))
      .getOrCreate()

    import spark.implicits._
    spark.sparkContext.setLogLevel("WARN")

    // schema –¥–ª—è JSON
    val finSchema = new StructType()
      .add("company", "string")
      .add("period", "string")
      .add("pe", "double")
      .add("roe", "double")

    val finDF = spark.readStream.format("kafka")
      .option("kafka.bootstrap.servers", "kafka:9092")
      .option("subscribe", "financial_data")
      .load()
      .selectExpr("CAST(value AS STRING)")
      .select(from_json($"value", finSchema).as("data"))
      .select("data.*")

    val textSchema = new StructType()
      .add("source","string").add("text","string")
      .add("sentiment", new StructType()
          .add("neg","double").add("neu","double").add("pos","double"))
      .add("topic","integer").add("ts","string")

    val textDF = spark.readStream.format("kafka")
      .option("kafka.bootstrap.servers", "kafka:9092")
      .option("subscribe", "text_features")
      .load()
      .selectExpr("CAST(value AS STRING)")
      .select(from_json($"value", textSchema).as("t"))
      .selectExpr("t.sentiment.pos as pos",
                  "t.sentiment.neg as neg",
                  "t.topic as topic",
                  "t.ts as ts")

    // –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –∑–∞ 1h –æ–∫–Ω–æ
    val textAgg = textDF
      .withWatermark("ts", "2 hours")
      .groupBy(window($"ts", "1 hour").as("w"))
      .agg(avg("pos").as("avg_pos"),
           avg("neg").as("avg_neg"),
           count("*").as("msg_cnt"))

    // join (–ø—Ä–∏–º–µ—Ä –ø—Ä–æ—Å—Ç–æ–π, —Ä–µ–∞–ª—å–Ω–æ–µ —Å–≤—è–∑—ã–≤–∞–Ω–∏–µ –ø–æ company/period)
    val features = finDF
      .join(textAgg)  // –∑–¥–µ—Å—å –Ω—É–∂–Ω–∞ –ª–æ–≥–∏–∫–∞ –º–∞–ø–ø–∏–Ω–≥–∞ –∫–æ–º–ø–∞–Ω–∏–∏!
      .withColumn("feature_vector",
        array($"pe",$"roe",$"avg_pos",$"avg_neg",$"msg_cnt"))

    // –ø–∏—à–µ–º –≤ Postgres feature_store
    val query = features.writeStream
      .foreachBatch { (batchDF, _) =>
        batchDF.write
          .format("jdbc")
          .option("url","jdbc:postgresql://postgres:5432/invest")
          .option("dbtable","features")
          .option("user","invest").option("password","invest")
          .mode("append").save()
      }
      .start()

    query.awaitTermination()
6¬†|¬†Model‚ÄëService¬†(PyTorch¬†+¬†scikit‚Äëlearn¬†+¬†FastAPI)
requirements.txt
makefile
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
fastapi
uvicorn[standard]
pydantic
torch==2.2.2
scikit-learn==1.5.0
pandas
psycopg2-binary
joblib
shap
train.py (–æ—Ñ–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏–µ)
python
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
import pandas as pd, torch, joblib
from sklearn.ensemble import RandomForestRegressor
from torch import nn
from sklearn.model_selection import train_test_split

df = pd.read_sql("select * from features", "postgresql://invest:invest@postgres/invest")
X = df.filter(regex="^feat_").to_numpy()
y = df["target"].to_numpy()          # —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è

# ----- RF -----
rf = RandomForestRegressor(n_estimators=200, n_jobs=-1).fit(X, y)
joblib.dump(rf, "rf.pkl")

# ----- DNN -----
class Net(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(dim, 128), nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64), nn.ReLU(),
            nn.Linear(64, 1)
        )
    def forward(self, x): return self.net(x)

net = Net(X.shape[1]); opt = torch.optim.Adam(net.parameters(), 1e-3)
loss_fn = nn.MSELoss()
Xt, Xv, yt, yv = train_test_split(X, y, test_size=.2, random_state=42)
Xt = torch.tensor(Xt).float(); yt = torch.tensor(yt).float().unsqueeze(1)
for epoch in range(20):
    net.train(); opt.zero_grad()
    pred = net(Xt); loss = loss_fn(pred, yt)
    loss.backward(); opt.step()

torch.save(net.state_dict(), "dnn.pt")
api.py
python
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import numpy as np, joblib, torch
from shap import TreeExplainer

class InVector(BaseModel):
    features: list[float]

rf = joblib.load("rf.pkl")
dnn_state = torch.load("dnn.pt", map_location="cpu")
dnn_dim = rf.n_features_in_             # –æ–¥–∏–Ω–∞–∫–æ–≤–æ
class Net(torch.nn.Module):
    def __init__(self, d): super().__init__()
    # —É–ø—Ä–æ—â–µ–Ω–æ: —Ç–∞ –∂–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, —á—Ç–æ –≤ train.py
Net.forward = lambda self,x: x  # placeholder
dnn = Net(dnn_dim); dnn.load_state_dict(dnn_state); dnn.eval()

explainer = TreeExplainer(rf)

app = FastAPI()

@app.post("/predict")
def predict(vec: InVector):
    x = np.array(vec.features).reshape(1,-1)
    rf_pred = rf.predict(x)[0]
    with torch.no_grad():
        dnn_pred = float(dnn(torch.tensor(x).float()))
    score = 0.6*dnn_pred + 0.4*rf_pred  # –ø—Ä–æ—Å—Ç–∞—è –º–µ—Ç–∞‚Äë–∞–≥—Ä–µ–≥–∞—Ü–∏—è
    return {"rf": rf_pred, "dnn": dnn_pred, "score": score}

@app.post("/shap")
def shap_values(vec: InVector):
    x = np.array(vec.features).reshape(1,-1)
    vals = explainer.shap_values(x)
    return {"shap": vals.tolist()}
7¬†|¬†Simulation‚ÄëService¬†(FastAPI)
app.py
python
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
import numpy as np, random
from fastapi import FastAPI
import requests, os

MODEL_EP = os.getenv("MODEL_EP","http://model-service:8001/predict")
app = FastAPI()

class Scenario(BaseModel):
    base: list[float]
    idx: int          # –∏–Ω–¥–µ–∫—Å –∏–∑–º–µ–Ω—è–µ–º–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
    delta: float      # –ø—Ä–∏—Ä–∞—â–µ–Ω–∏–µ
    iters: int = 5000

@app.post("/what-if")
def what_if(sc: Scenario):
    vec = sc.base[:]
    vec[sc.idx] += sc.delta
    return requests.post(MODEL_EP, json={"features": vec}).json()

@app.post("/monte-carlo")
def monte(sc: Scenario):
    base = np.array(sc.base)
    results = []
    for _ in range(sc.iters):
        noise = np.random.normal(0, 0.05, size=len(base))
        sample = (base * (1+noise)).tolist()
        res = requests.post(MODEL_EP, json={"features": sample}).json()
        results.append(res["score"])
    return {"mean": float(np.mean(results)),
            "std": float(np.std(results)),
            "p95": float(np.percentile(results, 95))}
8¬†|¬†API‚ÄëGateway¬†(FastAPI¬†+¬†JWT)
auth.py
python
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
from datetime import datetime, timedelta
import jwt, os, bcrypt, psycopg2
SECRET = os.getenv("JWT_SECRET","topsecret")
def create_token(user_id, role):
    payload = {"uid": user_id, "role": role,
               "exp": datetime.utcnow()+timedelta(hours=12)}
    return jwt.encode(payload, SECRET, algorithm="HS256")
def verify_token(token):
    return jwt.decode(token, SECRET, algorithms=["HS256"])
def hash_pw(pw: str): return bcrypt.hashpw(pw.encode(), bcrypt.gensalt())
def check_pw(pw: str, hashed): return bcrypt.checkpw(pw.encode(), hashed)
main.py (—Ñ—Ä–∞–≥–º–µ–Ω—Ç)
python
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
from fastapi import FastAPI, Depends, HTTPException, Header
from auth import verify_token, create_token
import psycopg2, os, redis, json, requests

app = FastAPI()
rdb = redis.Redis(host="redis", port=6379)

def require_auth(token=Header(...)):
    try: return verify_token(token)
    except Exception: raise HTTPException(401,"bad token")

@app.post("/login")
def login(user:str, pwd:str):
    conn = psycopg2.connect("dbname=invest user=invest password=invest host=postgres")
    cur = conn.cursor(); cur.execute("select id,pwd_hash,role from users where login=%s",(user,))
    row = cur.fetchone()
    if not row: raise HTTPException(401,"no user")
    if not check_pw(pwd,row[1].encode()): raise HTTPException(401,"bad pw")
    return {"token": create_token(row[0], row[2])}

@app.get("/companies")
def companies(auth=Depends(require_auth)):
    # –∫—ç—à–∏—Ä—É–µ–º 5 —Å–µ–∫
    cached = rdb.get("companies")
    if cached: return json.loads(cached)
    res = requests.get("http://model-service:8001/latest").json()
    rdb.setex("companies",5,json.dumps(res))
    return res
9¬†|¬†README¬†(—Ñ—Ä–∞–≥–º–µ–Ω—Ç)
md
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
### –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç –ª–æ–∫–∞–ª—å–Ω–æ

```bash
git clone https://github.com/yourname/invest-score && cd invest-score
cp .env.example .env          # –≤—Å—Ç–∞–≤—å—Ç–µ API‚Äë–∫–ª—é—á–∏
docker-compose up -d          # ~3‚Äë4‚ÄØ–º–∏–Ω
open http://localhost:3000    # SPA
–°–µ—Ä–≤–∏—Å	–ü–æ—Ä—Ç –ª–æ–∫–∞–ª—å–Ω–æ
API Gateway	http://localhost:8000
Model API	http://localhost:8001/predict
Simulation	http://localhost:8002
Kafka UI (–æ–ø—Ü.)	:9092 (–∫–µ–π—Å—ã)
PGAdmin (–æ–ø—Ü.)	:5050

–†—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
bash
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
curl -X POST localhost:8001/predict \
     -H "Content-Type: application/json" \
     -d '{"features":[1.2,3.4,0.5,0.1,15]}'
10¬†|¬†–ß—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å –¥–æ–¥–µ–ª–∞—Ç—å
–ü–æ–ª–Ω—ã–π Dockerfile –¥–ª—è Spark‚Äë–∫–ª–∞—Å—Ç–µ—Ä–∞ –∏ yaml Helm‚Äë—á–∞—Ä—Ç.

Hyperledger¬†Fabric: —Å–µ—Ç—å, chaincode –∏ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å‚Äëwriter.

CI/CD: .gitlab-ci.yml (–ª–∏–Ω—Ç, —Ç–µ—Å—Ç—ã, build ‚Üí Docker¬†registry).

–§—Ä–æ–Ω—Ç–µ–Ω–¥:

–ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (Auth, Companies, Company¬†Detail, Simulation).

–≥—Ä–∞—Ñ–∏–∫–∏¬†D3 –¥–ª—è SHAP –∏ Monte‚ÄëCarlo.

Unit‚Äëtests (pytest + ScalaTest).

Data mapping –≤ Spark¬†join (–ø—Ä–∏–≤—è–∑–∫–∞ —Ç–≤–∏—Ç–æ–≤ –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∫–æ–º–ø–∞–Ω–∏—è–º –ø–æ NER).

=== CONTINUE HERE ===








–í—ã —Å–∫–∞–∑–∞–ª–∏:
 CONTINUE HERE
–¢–ê–∫–∂–µ –ø—Ä–æ—è—Å–Ω–∏, –∫–∞–∫–∏–µ —Å—Ä–µ–¥—ã —Ä–∞–∑—Ä–∞–±–æ–∫—Ç–∏ —è –º–æ–≥—É –∏—Å–ø–æ–ª—å–∑–æ–≤—Ç–∞—å. –î–æ–ø—É—Å—Ç–∏–º –ª–∏ visual code (—è –Ω–µ –∑–Ω–∞—é —ç—Ç–æ—Ç –º–æ–º–µ–Ω—Ç –∏ –º–Ω–µ –¥–ø–æ–ª–Ω–∏—Ç–ª—å–Ω–∞—è –Ω—É–∂–Ω–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è —Å –∏–ø–∏—Å–∞–Ω–∏–µ–º —Ç–æ–≥–æ,—á—Ç–æ –º–Ω–µ –Ω—É–∂–Ω–æ –¥–µ–ª–∞—Ç—å). –Ø –ø–æ–ª—É—á–∞–µ—Ç—Å—è —Å–æ–∑–¥–∞—é –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ—Ç–µ–¥–Ω–ª—å–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–≤–æ–≤ –∞ —Ç–µ—Å—Ç–∏—Ä—É—é –∏—Ö –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ –∏–ª–∏ –∫–∞–∫?


ChatGPT —Å–∫–∞–∑–∞–ª:
=== CONTINUE HERE ===
11¬†|¬†–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã Spark –∏ Hyperledger¬†Fabric
11.1¬†Dockerfile (spark-job/Dockerfile)
dockerfile
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
FROM bitnami/spark:3.5.1

USER root
RUN apt-get update && apt-get install -y openjdk-17-jdk scala

# –ö–æ–ø–∏—Ä—É–µ–º JAR‚Äë–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
COPY target/scala-3.3.3/streamingjob_3-0.1.jar /opt/spark/jobs/

# –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ ‚Äì –∑–∞–ø—É—Å–∫ StreamingJob
ENTRYPOINT ["/opt/bitnami/scripts/spark/entrypoint.sh"]
CMD ["spark-submit","--class","StreamingJob","/opt/spark/jobs/streamingjob_3-0.1.jar"]
–í docker-compose.yml –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å —Å–µ—Ä–≤–∏—Å spark-job —ç—Ç–æ–π —Å–±–æ—Ä–∫–æ–π
–∏–ª–∏ –≤—ã–Ω–µ—Å—Ç–∏ Spark‚Äë–∫–ª–∞—Å—Ç–µ—Ä –≤ Helm‚Äë—á–∞—Ä—Ç (charts/spark/values.yaml).

11.2¬†Fabric¬†‚Äì docker‚Äëcompose.override.yml (–º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å–µ—Ç—å)
yaml
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
fabric-ca:
  image: hyperledger/fabric-ca:1.5
  command: sh -c 'fabric-ca-server start -b admin:adminpw'
  ports: ["7054:7054"]

peer0.org1:
  image: hyperledger/fabric-peer:2.5
  environment:
    - CORE_PEER_ID=peer0.org1
    - CORE_LEDGER_STATE_STATEDATABASE=CouchDB
  ports: ["7051:7051"]

orderer:
  image: hyperledger/fabric-orderer:2.5
  environment:
    - ORDERER_GENERAL_LISTENPORT=7050
  ports: ["7050:7050"]

fabric-writer:
  build: ./fabric-writer    # –º–∞–ª–µ–Ω—å–∫–∏–π Python‚Äë–∫–ª–∏–µ–Ω—Ç SDK
  depends_on: [peer0.org1, orderer, fabric-ca]
fabric-writer/chaincode/hashstore.go (—Å–∫–µ–ª–µ—Ç)
go
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
package main
import "github.com/hyperledger/fabric-contract-api-go/contractapi"

type HashStore struct{ contractapi.Contract }

func (hs *HashStore) Record(ctx contractapi.TransactionContextInterface,
    id string, hash string, ts string) error {
  return ctx.GetStub().PutState(id, []byte(hash+"|"+ts))
}
func (hs *HashStore) Get(ctx contractapi.TransactionContextInterface,
    id string) (string, error) {
  b, err := ctx.GetStub().GetState(id); return string(b), err }

func main() { cc, _ := contractapi.NewChaincode(new(HashStore)); cc.Start() }
12¬†|¬†CI/CD —Å–∫–µ–ª–µ—Ç (.gitlab-ci.yml)
yaml
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
stages: [lint,test,build,push]

variables:
  REGISTRY: registry.gitlab.com/$CI_PROJECT_PATH

lint:
  image: python:3.11
  stage: lint
  script: pip install black flake8 && flake8 ingest/ nlp-service/

pytest:
  image: python:3.11
  stage: test
  script: pip install -r ingest/requirements.txt pytest && pytest tests/

docker-build-push:
  stage: build
  image: docker:24
  services: [docker:24-dind]
  script:
    - docker login -u gitlab-ci-token -p $CI_BUILD_TOKEN $REGISTRY
    - docker build -t $REGISTRY/ingest:$CI_COMMIT_SHORT_SHA ingest/
    - docker push $REGISTRY/ingest:$CI_COMMIT_SHORT_SHA
üîß‚ÄØ–¥–æ–ø–æ–ª–Ω–∏—Ç—å Job‚Äë–∏ –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤ –∏ Helm‚Äëdeploy –≤ production‚Äënamespace.

13¬†|¬†–§—Ä–æ–Ω—Ç–µ–Ω–¥¬†(React¬†+¬†Vite)
pgsql
–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å
–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
web-ui/
‚îú‚îÄ‚îÄ index.html
‚îú‚îÄ‚îÄ src/
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ App.tsx
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pages/
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ Login.tsx
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ Companies.tsx
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ CompanyDetail.tsx
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ api.ts
‚îú‚îÄ‚îÄ vite.config.ts
‚îî‚îÄ‚îÄ Dockerfile
api.ts ‚Äì thin wrapper –Ω–∞–¥ REST‚Äë—ç–Ω–¥–ø–æ–∏–Ω—Ç–∞–º–∏; —Ö—Ä–∞–Ω–∏—Ç JWT –≤ localStorage.
CompanyDetail –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫—É react-chartjs‚Äë2 –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ SHAP –∏ –ú–æ–Ω—Ç–µ‚Äë–ö–∞—Ä–ª–æ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º.

14¬†|¬†–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
–®–∞–≥	–ß—Ç–æ —Å–¥–µ–ª–∞—Ç—å	–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
1	–ö–ª–æ–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–ø–æ: git clone ‚Ä¶	Git
2	–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Docker¬†+¬†Docker¬†Compose (–∏–ª–∏ Podman)	Docker Desktop / podman
3	(–æ–ø—Ü.) –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å VS¬†Code + —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è:
‚Ä¢¬†Python
‚Ä¢¬†Docker
‚Ä¢¬†Remote¬†‚Äì¬†Containers
‚Ä¢¬†Dev¬†Containers	VSCode
4	–°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å .env.example ‚Üí .env, –≤–ø–∏—Å–∞—Ç—å –∫–ª—é—á–∏ Twitter/Telegram, JWT_SECRET	nano/vscode
5	–ó–∞–ø—É—Å—Ç–∏—Ç—å –≤–µ—Å—å —Å—Ç–µ–∫: docker-compose up -d	Terminal
6	–û—Ç–∫—Ä—ã—Ç—å http://localhost:3000 ‚Äì –≤–æ–π—Ç–∏ admin/admin	Browser
7	–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞: –æ—Ç–∫—Ä–æ–π—Ç–µ –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞ –≤ VS¬†Code.
–ü—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ DevContainer¬†(.devcontainer.json) VS¬†Code —Å–∞–º –ø—Ä–µ–¥–ª–æ–∂–∏—Ç Reopen in Container ‚Äì –ø–æ–ª—É—á–∏—Ç–µ –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ Python+Java –≤–Ω—É—Ç—Ä–∏ Docker, –Ω–µ¬†–ª–æ–º–∞—è –ª–æ–∫–∞–ª—å–Ω—ã–π –ü–ö.	VSCode Dev¬†Container
8	–î–ª—è –æ—Ç–ª–∞–¥–∫–∏ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞:
docker compose stop nlp-service ‚Üí cd nlp-service ‚Üí uvicorn app:app --reload --host 0.0.0.0 --port 8005 –∏ –∏–∑–º–µ–Ω—è–π—Ç–µ –∫–æ–¥, –∞–≤—Ç–æ‚Äëreload –º–≥–Ω–æ–≤–µ–Ω–Ω–æ –æ–±–Ω–æ–≤–∏—Ç.	VSCode¬†/ PyCharm
9	–¢–µ—Å—Ç—ã: pytest tests/ –≤ –∫–æ—Ä–Ω–µ –∏–ª–∏ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø–∞–ø–∫–µ.	pytest
10	–°–±–æ—Ä–∫–∞ —Ñ—Ä–æ–Ω—Ç–∞: cd web-ui && npm i && npm run build ‚Äì —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ø–∞–¥–∞–µ—Ç –≤ web-ui/dist, –∫–æ—Ç–æ—Ä—ã–π –º–æ–Ω—Ç–∏—Ä—É–µ—Ç—Å—è –≤ nginx‚Äë–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä.	Node¬†18

Monorepo vs –º—É–ª—å—Ç–∏‚Äë—Ä–µ–ø–æ?
–ü—Ä–æ–µ–∫—Ç –∏–¥—ë—Ç –º–æ–Ω–æ—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–º (invest-score/).
–ö–∞–∂–¥—ã–π –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å –ª–µ–∂–∏—Ç –≤ —Å–≤–æ–µ–π –ø–∞–ø–∫–µ, –Ω–æ –≤—Å—ë –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä—É–µ—Ç—Å—è –≤–º–µ—Å—Ç–µ ‚Äì —É–¥–æ–±–Ω–æ –¥–µ—Ä–∂–∞—Ç—å Docker‚ÄëCompose –∏ shared‚Äë.env.
–ï—Å–ª–∏ –∑–∞—Ö–æ—Ç–∏—Ç–µ —Ä–∞–∑–Ω–µ—Å—Ç–∏ ‚Äì –≤—ã–¥–µ–ª–∏—Ç–µ ingest/, nlp-service/ –∏¬†—Ç.–¥. –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ Git‚Äë–ø—Ä–æ–µ–∫—Ç—ã, –∑–∞–º–µ–Ω–∏—Ç–µ –≤ CI –ø—É—Ç–∏.

15¬†|¬†–í—ã–±–æ—Ä —Å—Ä–µ–¥—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
–Ø–∑—ã–∫	–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è IDE	–ü—Ä–∏—á–∏–Ω–∞
Python‚Äë–º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å—ã	VS¬†Code (Ext: Python, Pylance) –∏–ª–∏ PyCharm¬†Professional	–ê–≤—Ç–æ‚Äë—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (Black), –¥–µ–±–∞–≥ —á–µ—Ä–µ–∑ Docker‚Äë–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é
Scala/Java (Spark)	IntelliJ¬†IDEA + –ø–ª–∞–≥–∏–Ω Scala	–£–º–Ω–∞—è –ø–æ–¥—Å–≤–µ—Ç–∫–∞, —Å–±–æ—Ä–∫–∞ SBT/Gradle
–§—Ä–æ–Ω—Ç–µ–Ω–¥ (React)	VS¬†Code + ESLint¬†/ Prettier	Hot‚Äëreload Vite

–ú–æ–∂–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤ VS¬†Code¬†+¬†Dev¬†Containers:
–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å–æ–¥–µ—Ä–∂–∏—Ç Python¬†3.11, Node¬†18, Java¬†17 –∏ sbt¬†1.9¬†‚Äì –≤—ã –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç–µ —Ä–µ–¥–∞–∫—Ç–æ—Ä, –∞ –∫–æ–¥ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –≤¬†–¥–æ–∫–µ—Ä–µ.
–¢–∞–∫ —É–¥–æ–±–Ω–æ, –µ—Å–ª–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –≤–µ–¥—ë—Ç—Å—è –Ω–∞ Windows: –≤—Å—ë Linux‚Äë–æ–∫—Ä—É–∂–µ–Ω–∏–µ —É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ.

16¬†|¬†–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
Unit‚Äëtests
Python: pytest –¥–ª—è ingest, NLP, model‚Äëservice (–∑–∞–≥–ª—É—à–∫–∞ –º–æ–¥–µ–ª–µ–π ‚Üí —Ñ–∏–∫—Ç–∏–≤–Ω—ã–π –≤—ã–≤–æ–¥).
Scala: sbt test + ScalaTest ‚Äì –ø—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏–∫—É –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è Spark.

Integration‚Äëtests
–°–∫—Ä–∏–ø—Ç tests/integration/test_pipeline.py:

–±—Ä–æ—Å–∞–µ—Ç CSV –≤ –ø–∞–ø–∫—É /data

–∂–¥—ë—Ç Kafka‚Äë—Å–æ–æ–±—â–µ–Ω–∏—è financial_data

–ø—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ Spark –∑–∞–ø–∏—à–µ—Ç —Å—Ç—Ä–æ–∫—É –≤ —Ç–∞–±–ª–∏—Ü—É features.

E2E
cypress —Å—Ü–µ–Ω–∞—Ä–∏–π: –ª–æ–≥–∏–Ω ‚Üí –ø—Ä–æ—Å–º–æ—Ç—Ä —Ä–µ–π—Ç–∏–Ω–≥–∞ ‚Üí –∑–∞–ø—É—Å–∫ what-if ‚Üí –ø—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞—Ñ–∏–∫–∞.

Load test
K6/Locust ‚Äì 2k¬†rps –ø—Ä–æ—Ç–∏–≤ /companies, latency <‚ÄØ50‚ÄØms (–ø—Ä–∏ –≤–∫–ª—é—á—ë–Ω–Ω–æ–º Redis).

17¬†|¬†–î–æ—Ä–æ–∂–Ω–∞—è –∫–∞—Ä—Ç–∞ –¥–æ prod‚ÄØv1
–ë–ª–æ–∫	–°—Ç–∞—Ç—É—Å	–û—Å—Ç–∞–ª–æ—Å—å
–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö	‚úÖ¬†MVP –≥–æ—Ç–æ–≤	‚Üí¬†YAML –∫–∞–Ω–∞–ª–æ–≤ –∏–∑ UI
NLP	‚úÖ¬†sentiment/BERTopic	‚Üí¬†–¥–æ–æ–±—É—á–∏—Ç—å NER –Ω–∞ –æ—Ç—Ä–∞—Å–ª—å
Spark	‚úÖ¬†basic join	‚Üí¬†map tweets ‚Üí¬†company –ø–æ NER
ML	‚úÖ¬†–¥–≤–µ –º–æ–¥–µ–ª–∏ + –∞–≥—Ä–µ–≥–∞—Ü–∏—è	‚Üí¬†stacking¬†GBM, auto‚Äëretrain schedule
Fabric	‚¨ú¬†–¥–µ–ø–ª–æ–π	‚Üí¬†–≥–µ–Ω–µ—Ä–∞—Ü–∏—è cryptomaterials, CI tx test
UI	üü°¬†—Ç–∞–±–ª–∏—Ü–∞+auth	‚Üí¬†–≥—Ä–∞—Ñ–∏–∫–∏ SHAP, Monte¬†Carlo –≤–∏–∑—ã
CI/CD	üü°¬†lint+build	‚Üí¬†Helm¬†deploy stage
Docs	üü°¬†README	‚Üí¬†Swagger¬†/OpenAPI –æ–ø–∏—Å–∞–Ω–∏–µ

–ì–æ—Ç–æ–≤–æ.
–£ –≤–∞—Å –µ—Å—Ç—å —Ä–∞–±–æ—á–∏–π —à–∞–±–ª–æ–Ω –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã:
‚Ä¢¬†–≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã –ø–æ–¥–Ω–∏–º–∞—é—Ç—Å—è docker‚Äëcompose up ‚Äìd
‚Ä¢¬†–¥–æ—Å—Ç—É–ø–Ω—ã REST‚Äë—ç–Ω–¥–ø–æ–∏–Ω—Ç—ã /predict, /companies, /what-if, /monte-carlo
‚Ä¢¬†–≥–æ—Ç–æ–≤ Dev‚Äëflow –ø–æ–¥ VS¬†Code –∏–ª–∏ JetBrains.

–î–∞–ª—å–Ω–µ–π—à–∞—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞¬†‚Äì —Å–æ–≥–ª–∞—Å–Ω–æ —á–µ–∫‚Äë–ª–∏—Å—Ç—É –≤ –ø.‚ÄØ17. –ï—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–Ω—É—Ç –≤–æ–ø—Ä–æ—Å—ã –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ, –¥–∞–π—Ç–µ –∑–Ω–∞—Ç—å!








